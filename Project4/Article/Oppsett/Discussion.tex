\section{Discussion}
%Oppgave 4d
Figures \ref{econvergence} and \ref{mconvergence} show a clear trend in equilibration times for both the mean energy and mean magnetization for ordered and disordered systems. In both cases, for the 'cold' temperature $k_B T = 1\ J$, the systems initialized with ordered (ground state) spin configurations are already at equilibrium. Initializing the systems with ordered configurations (all up/all down) leads to only one possible energy change when proposing new configurations, being $\Delta E = 8J$. Hence, in all trials, the energy is never smaller than zero and so we do not immediately accept proposed configurational transitions. The algorithm will instead in each trial test random numbers against the distribution function, which leads to very low acceptance ratios. The ground state initialization for cold systems is therefore very stable. For an initially disordered configuration, we see that the system still quickly reaches equilibrium. An initially disordered configurations leads to more possible energy changes when flipping single spin sites, which dramatically increases the acceptance ratio in each trial. Still, the initial configuration is significantly different from the steady state configuration, which consequentially requires the algorithm to propose many different configurations before reaching the steady state configuration. Once steady state has been achieved, the situation is similar as for the initially ordered system - the acceptance ratio becomes very low. 

The situation is a bit different for the 'hotter' temperature $k_B T = 2.4\ J$. As can be seen from the plots, the system never completely stabilizes for the number of MCS used in these specific calculations. We here present the obtained data for $10^4$ cycles only as this data clearly displays the oscillatory behaviour as the system converges towards a steady state.  Therefore, an arbitrary degree of accuracy has to be chosen for what is considered an equilibrium state. For the mean energy in the right side of Figure \ref{econvergence}, it seems that after 3500 MCS, the two systems are fairly stable and seems to be oscillating around the same value. The same number of MCS can be accepted as the equilibration period for the mean magnetization in the right of Figure \ref{mconvergence}, although the oscillations around the equilibrium value are larger in magnitude.\\


As we may see in Figure \ref{fig:expvals}, the solutions for $\langle E \rangle$ and $\langle |M| \rangle$ for different lattice sizes are well behaved across the entire temperature interval. The solutions for $C_V$ and $\mathcal{X}$ are fairly well behaved for smaller lattices like the "40x40" and "60x60" system. For larger lattices, however, like the "80x80" and "100x100" considered here, the solutions deviate from the same "smooth" evolution towards the critical temperature from the very beginning of the simulation. We suspect that this has to do with a numerical phenomenon known as \textit{critical slowing down} of the Metropolis Algorithm \cite{walter}, \cite{carlon},\cite{gould}. To better grasp the idea of this concept, consider the figure below

\begin{figure}[H]
    \centering
    \includegraphics[width = \linewidth]{Figure/magdomains.png}
    \caption{Plot of magnetic domains in a 100x100 spin lattice at different temperatures $k_B T = 1.0 J$ (left), $k_B T \sim T_C$ (middle) and $k_B T = 2.6 J$ (right). The red color represents the spin down attribute at a lattice site, and the black color represents the spin up attributes. }
    \label{fig:domains}
\end{figure}

Figure \ref{fig:domains} illustrates the formation of magnetic domains in a spin lattice, and how such clusters of aligned spins form accordingly with temperature. As we presented in Figure \ref{fig:expvals}, the absolute magnetization of the spin lattice incrementally evolves towards zero - id est a state in which there are equal amounts of spin up and spin down sites. The rightmost figure in \ref{fig:domains} indicates that the system follows such an evolution, as the spin clusters become more evenly distributed in size\footnote{This behaviour would have been more easily recognized had we simulated the system over a larger temperature interval such that the final temperature had been much larger than the initial temperature.}. Nevertheless, the most important feature of this spin cluster model in this context is that around the critical temperature, the spin lattice consists of many, unevenly distributed domains of aligned spins. When performing random sampling at this temperature, the single spin flip dynamic we devise in this algorithm leads to an exceptionally low acceptance rate. Consider, like before the 2D Ising model in which a spin center has four nearest neighbors. At $T_C$, such spin centers have four nearest neighbors which are all aligned with the spin center, with the exception of spin centers located at the boundary of two spin domains. Flipping the spin center leads to a change in the local energy contribution of size $\Delta E = 8J$ as we discussed in Section 3.2, committing to an acceptance rate $A(i \to j) = \exp(-8\beta_C) \approx 0.03$ for $\beta_C = 1/(k_B T_C)$ where $T_C$ holds the approximate value $T_C \approx 2.269$. Worse still, given that a local spin center in a spin cluster is flipped by chance, sampling this local spin configuration in a later Monte Carlo Sweep guarantees that the spin will be flipped back as this proposed transition carries a local energy change $\Delta E = -8J < 0$, which the algorithm accepts without exception. The odds of transitioning between many states in configuration space and sampling a decent amount of significantly incoherent data are very much stacked against us at temperatures around $T_C$, all due to the critical slow down of the Metropolis algorithm stemming from the formation of aligned spin clusters.\\

As we can see, sweeping through the lattice, each time seeding a random lattice site, the spin cluster formation manifests strong correlation between two proposed configurations. The critical slowing down of the Metropolis algorithm is largely dictated by the \textit{correlation time}. The correlation time $\tau$, in units of Monte Carlo Sweeps per lattice point, is an approximate measure of how many iterations that are necessary for two different configurations to be significantly incoherent. For sufficiently large lattices with single spin flip dynamics, the correlation time is given by

\[
\tau \sim \mathcal{L}^{z_c}
\]
where $\mathcal{L}$ is the size of the lattice, and $z_c$ is the \textit{critical dynamical exponent} which Nightingale and BlÃ¶te obtained as $z_c = 2.1665(12)$ for single spin flip dynamics in the square spin lattice case \cite{nightingale}. The correlation time is a much more accurate representation of the actual equilibration time $t$, an important quantity which we crudely have determined by visual inspection in this project. Inspecting $\tau$, we see that the correlation time between a two states is close to ten thousand Monte Carlo sweeps \textit{per lattice site}, leading up to the fact that a total of one hundred million Monte Carlo sweeps would suffice for random sampling of incoherent states, which in turn would lead to significantly more accurate data. In light of the time it took to run the program using a total of ten million cycles for the 80x80 and 100x100 systems for our rather high temperature resolution, amping up the total number of Monte Carlo cycles is a study prospect for our future selves. In our research we have found that so called 'cluster algorithms' established by Wolff, as well as Swendsen and Wang \cite{walter} solve this issue by flipping entire clusters of aligned spins rather than singular spins.\\

Although the data obtained for the larger systems in this study is far less accurate than desired, these solutions too commit a clear indication of where the system undergoes a phase transition, which was helpful in the numerical extraction of the critical temperature. By determining the temperatures for which each curve describing either $\mathcal{X}$ and $C_V$ have a clear maximum value, the true value of the critical temperature $T_C$ may be found through the relationship \eqref{critical2} described in Section \ref{sectioncritical}. These temperatures are given in Table \ref{tab:Tc_susc} and a plot of the data alongside with the the associated linear regression is shown in Figure \ref{fig:tcritical}. We found the critical temperature for an infinite lattice to be $2.289$, whereas the analytical value obtained by Onsager is $\approx 2.269$. This is an error of just $0.8$\%, and therefore a very good approximation. By running the program for larger lattice sizes ($\mathcal{L} > 100$), and also taking the longer correlation times into consideration such that the data displays singular global maxima, an even better approximation could be made.